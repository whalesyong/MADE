{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADE Results Analysis\n",
    "\n",
    "This notebook demonstrates how to load and analyze results from MADE benchmark runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from results_analysis_utils import (\n",
    "    load_single_run_results,\n",
    "    load_baseline_results,\n",
    "    load_baseline_overall_summary,\n",
    "    load_baseline_per_system_summary,\n",
    "    load_experiment_metadata,\n",
    "    load_experiment_progress,\n",
    "    load_summary,\n",
    "    plot_discovery_curves,\n",
    "    plot_final_metrics_comparison,\n",
    "    results_to_dataframe,\n",
    "    STRATEGY_LABELS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Results from a Single Run\n",
    "\n",
    "Results from `run_benchmark.py` are saved in a timestamped directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent results directory\n",
    "results_base = Path(\"../results\")\n",
    "run_dirs = sorted([d for d in results_base.iterdir() if d.is_dir() and not d.name.startswith(\"baselines\")])\n",
    "\n",
    "if run_dirs:\n",
    "    latest_run = run_dirs[-1]\n",
    "    print(f\"Loading results from: {latest_run.name}\")\n",
    "else:\n",
    "    print(\"No results found. Run a benchmark first with: uv run scripts/run_benchmark.py\")\n",
    "    latest_run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest_run:\n",
    "    # Load episode trajectories\n",
    "    metrics_histories, final_metrics_list = load_single_run_results(latest_run, verbose=True)\n",
    "    print(f\"Loaded {len(metrics_histories)} episodes\")\n",
    "    \n",
    "    # Load summary statistics\n",
    "    summary = load_summary(latest_run)\n",
    "    if summary:\n",
    "        print(f\"\\nSummary metrics (showing key discovery metrics):\")\n",
    "        key_metrics = [\n",
    "            \"final/novelty_stable_unique_novel_count\",\n",
    "            \"final/novelty_stable_unique_novel_fraction\",\n",
    "            \"final/recall_formula\",\n",
    "            \"final/precision_formula\",\n",
    "            \"final/area_under_discovery_curve_normalized\",\n",
    "        ]\n",
    "        for key in key_metrics:\n",
    "            if key in summary:\n",
    "                value = summary[key]\n",
    "                clean_key = key.replace(\"final/\", \"\")\n",
    "                print(f\"  {clean_key}: {value['mean']:.3f} \u00b1 {value.get('sem', 0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot Discovery Curves\n",
    "\n",
    "Discovery curves show the cumulative number of stable structures discovered vs oracle queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest_run and metrics_histories:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    plot_discovery_curves(metrics_histories, label=\"Agent\", ax=ax)\n",
    "    ax.set_title(f\"Discovery Curve - {latest_run.name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Final Metrics Comparison\n",
    "\n",
    "Compare final metrics across episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest_run and final_metrics_list:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plot_final_metrics_comparison(final_metrics_list, ax=ax)\n",
    "    ax.set_title(\"Final Metrics (Mean \u00b1 Std across Episodes)\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}